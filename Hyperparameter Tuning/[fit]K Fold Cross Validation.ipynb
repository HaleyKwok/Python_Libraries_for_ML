{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a0ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1 \n",
    "# use all available data for training and testing on same dataset\n",
    "# e.g., 100 math questions prepared, and a few questions to be tested\n",
    "# option 2\n",
    "# 70/100 for training and 30/100 for testing \n",
    "\n",
    "# option 3\n",
    "# K-fold cross vaildation\n",
    "# 1000 samples 20/100 for testing and 80/100 for training x 5 sets\n",
    "# take average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e4675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "digits = load_digits()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,digits.target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa44ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every time you reexectue it, the score changed. You cannot only run more time since the \n",
    "# dataset split everytime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d512bd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nsolver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'\\n\\n        - For small datasets, 'liblinear' is a good choice, whereas 'sag'\\n          and 'saga' are faster for large ones;\\n        - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\\n          'lbfgs' handle multinomial loss;\\n        - 'liblinear' is limited to one-versus-rest schemes.\\n\\n    .. warning::\\n       The choice of the algorithm depends on the penalty chosen:\\n       Supported penalties by solver:\\n\\n       - 'newton-cg'   -   ['l2', 'none']\\n       - 'lbfgs'       -   ['l2', 'none']\\n       - 'liblinear'   -   ['l1', 'l2']\\n       - 'sag'         -   ['l2', 'none']\\n       - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']\\n\\nmulti_class : {'auto', 'ovr', 'multinomial'}, default='auto'\\n    If the option chosen is 'ovr', then a binary problem is fit for each\\n    label.\\n    \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(solver='liblinear',multi_class='ovr')\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'\n",
    "\n",
    "        - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
    "          and 'saga' are faster for large ones;\n",
    "        - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
    "          'lbfgs' handle multinomial loss;\n",
    "        - 'liblinear' is limited to one-versus-rest schemes.\n",
    "\n",
    "    .. warning::\n",
    "       The choice of the algorithm depends on the penalty chosen:\n",
    "       Supported penalties by solver:\n",
    "\n",
    "       - 'newton-cg'   -   ['l2', 'none']\n",
    "       - 'lbfgs'       -   ['l2', 'none']\n",
    "       - 'liblinear'   -   ['l1', 'l2']\n",
    "       - 'sag'         -   ['l2', 'none']\n",
    "       - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']\n",
    "\n",
    "multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
    "    If the option chosen is 'ovr', then a binary problem is fit for each\n",
    "    label.\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb97a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5092592592592593"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "svm = SVC(gamma='auto')\n",
    "svm.fit(X_train, y_train)\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e96c451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975925925925926"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=40)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e063f",
   "metadata": {},
   "source": [
    "# KFold cross validation\n",
    "- Basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62661b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3) # 3 sets\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cbfd2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8] [0 1 2]\n",
      "[0 1 2 6 7 8] [3 4 5]\n",
      "[0 1 2 3 4 5] [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810dbf45",
   "metadata": {},
   "source": [
    "# Use KFold for our digits example\n",
    "- just for explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079fa44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model, X_train, X_test, y_train, y_test): # take model first..\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f6f6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=3)\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "\n",
    "for train_index, test_index in folds.split(digits.data,digits.target):\n",
    "    X_train, X_test, y_train, y_test = digits.data[train_index], digits.data[test_index], \\\n",
    "                                       digits.target[train_index], digits.target[test_index]\n",
    "    scores_logistic.append(get_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X_train, X_test, y_train, y_test))  \n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X_train, X_test, y_train, y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8bc606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8948247078464107, 0.9532554257095158, 0.9098497495826378]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0456545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3806343906510851, 0.41068447412353926, 0.5125208681135225]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d03f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9298831385642737, 0.9515859766277128, 0.9198664440734557]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc148f",
   "metadata": {},
   "source": [
    "# cross_val_score function\n",
    "- we use this in reality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20115164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cross_val_score uses stratifield kfold by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4e7b2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89482471, 0.95325543, 0.90984975])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression model performance using cross_val_score\n",
    "cross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'), digits.data, digits.target,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "796895bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38063439, 0.41068447, 0.51252087])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm model performance using cross_val_score\n",
    "cross_val_score(SVC(gamma='auto'), digits.data, digits.target,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "784ed53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94490818, 0.95659432, 0.92320534])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest performance using cross_val_score\n",
    "cross_val_score(RandomForestClassifier(n_estimators=40),digits.data, digits.target,cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf96f1",
   "metadata": {},
   "source": [
    "# Parameter tunning using k fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0947be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8664525139664805"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 = cross_val_score(RandomForestClassifier(n_estimators=5),digits.data, digits.target, cv=10)\n",
    "np.average(scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3dfac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393420235878336"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2 = cross_val_score(RandomForestClassifier(n_estimators=20),digits.data, digits.target, cv=10)\n",
    "np.average(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6f87820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941548727498448"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores3 = cross_val_score(RandomForestClassifier(n_estimators=30),digits.data, digits.target, cv=10)\n",
    "np.average(scores3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffda9d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459993792675357"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores4 = cross_val_score(RandomForestClassifier(n_estimators=40),digits.data, digits.target, cv=10)\n",
    "np.average(scores4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b877647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the average score of_5_is': 0.8870360024829299,\n",
       " 'the average score of_20_is': 0.9348758535071383,\n",
       " 'the average score of_30_is': 0.9393420235878335,\n",
       " 'the average score of_40_is': 0.9471229050279328}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we used cross_val_score to fine tune our random forest classifier and \n",
    "# figured that having around 40 trees in random forest gives best result.\n",
    "\n",
    "n_estimators=[5,20,30,40]\n",
    "average_scores ={}\n",
    "for ne in n_estimators:\n",
    "    cv_scores = cross_val_score(RandomForestClassifier(n_estimators=ne),digits.data, digits.target, cv=10)\n",
    "    average_scores['the average score of' +'_'+str(ne)+'_'+'is'] = np.average(cv_scores)\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62929dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
